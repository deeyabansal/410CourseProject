MP2.2 covers annotation of the collection created in MP2.1 to create a set of queries and the corresponding relevance judgments. The outcome of MP2.2 is a test set that can be used to quantitatively evaluate a search engine algorithm
For MP2.2, you will use the CS410 DL Search Engine website to submit relevance judgments for a given query. Upon searching a query, you should see something like this (the UI will be updated mid-morning on 9/12):
Your job is to examine the search results and provide your relevance judgments (i.e., if a result answers your query). After you select "Relevant" or "Not Relevant" for the returned results, you should click "Submit Relevance Judgments" which will notify you of the status of the submission.
For full credit, you must submit at least 5 queries, each with at least 10 relevance judgments (or up to the number of returned results). That is, for each different query, you mark relevant/not relevant for at least ten results. The judged results do not need to be contiguous. 
We ask that you avoid trivial queries. Specific queries like "intuitive videos of bm25" or "startups doing nlp" are encouraged. Try to come up with queries that reflect your actual information needs, so that reading and judging results can also help you better understand the course material.
Grading for this assignment will be updated on Coursera once the assignment is due. You should be able to track the number of submitted judgments on the "Your Submissions" page.  If you have at least five judgments, you should receive full credit.
Note that you do not need to use LiveDataLab or submit anything on GitHub. Everything for MP2.2 is done via the CS410 Digital Library.
